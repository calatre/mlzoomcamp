{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea35b2e2",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Lead scoring dataset Bank Marketing dataset. [Download](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv).\n",
    "\n",
    "With `wget`:\n",
    "\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
    "```\n",
    "> I downloaded in the terminal to my ../data folder\n",
    "\n",
    "In this dataset our desired target for classification task will be `converted` variable - has the client signed up to the platform or not.\n",
    "\n",
    "### Data preparation\n",
    "\n",
    "* Check if the missing values are presented in the features.\n",
    "* If there are missing values:\n",
    "    * For categorical features, replace them with 'NA'\n",
    "    * For numerical features, replace with with 0.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "054deb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('../data/course_lead_scoring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24050991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "7114e602-4073-4d69-b309-c4868e9e1411",
       "rows": [
        [
         "lead_source",
         "128"
        ],
        [
         "industry",
         "134"
        ],
        [
         "number_of_courses_viewed",
         "0"
        ],
        [
         "annual_income",
         "181"
        ],
        [
         "employment_status",
         "100"
        ],
        [
         "location",
         "63"
        ],
        [
         "interaction_count",
         "0"
        ],
        [
         "lead_score",
         "0"
        ],
        [
         "converted",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 9
       }
      },
      "text/plain": [
       "lead_source                 128\n",
       "industry                    134\n",
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "employment_status           100\n",
       "location                     63\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "converted                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "#df.shape\n",
    "\n",
    "#data already looks neat with lowercase, underscores, etc\n",
    "#checking for missing values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b13d80c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "97bcc953-5711-44b8-883f-9d87f71c84a1",
       "rows": [
        [
         "number_of_courses_viewed",
         "0"
        ],
        [
         "annual_income",
         "181"
        ],
        [
         "interaction_count",
         "0"
        ],
        [
         "lead_score",
         "0"
        ],
        [
         "converted",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/plain": [
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "converted                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split categorical and numerical columns for different NA processing\n",
    "\n",
    "df.dtypes\n",
    "\n",
    "categorical_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "numerical_columns = list(df.dtypes[df.dtypes != 'object'].index)\n",
    "\n",
    "df[categorical_columns].isnull().sum()\n",
    "df[numerical_columns].isnull().sum()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3789a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical_columns] = df[categorical_columns].fillna('NA')\n",
    "df[numerical_columns] = df[numerical_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fda882",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "### Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column `industry`?\n",
    "\n",
    "- `NA`\n",
    "- `technology`\n",
    "- `healthcare`\n",
    "- `retail` <---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7bd0027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "industry",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2a7b68df-c3d7-46fd-ac00-f3dddea5ac45",
       "rows": [
        [
         "retail",
         "203"
        ],
        [
         "finance",
         "200"
        ],
        [
         "other",
         "198"
        ],
        [
         "healthcare",
         "187"
        ],
        [
         "education",
         "187"
        ],
        [
         "technology",
         "179"
        ],
        [
         "manufacturing",
         "174"
        ],
        [
         "NA",
         "134"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 8
       }
      },
      "text/plain": [
       "industry\n",
       "retail           203\n",
       "finance          200\n",
       "other            198\n",
       "healthcare       187\n",
       "education        187\n",
       "technology       179\n",
       "manufacturing    174\n",
       "NA               134\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['industry'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbcff34",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Create the [correlation matrix](https://www.google.com/search?q=correlation+matrix) for the numerical features of your dataset.\n",
    "In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "\n",
    "What are the two features that have the biggest correlation?\n",
    "\n",
    "- `interaction_count` and `lead_score`\n",
    "- `number_of_courses_viewed` and `lead_score`\n",
    "- `number_of_courses_viewed` and `interaction_count`\n",
    "- `annual_income` and `interaction_count`  <---\n",
    "\n",
    "Only consider the pairs above when answering this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f95fe2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          number_of_courses_viewed  annual_income  \\\n",
      "number_of_courses_viewed                  1.000000       0.009770   \n",
      "annual_income                             0.009770       1.000000   \n",
      "interaction_count                        -0.023565       0.027036   \n",
      "lead_score                               -0.004879       0.015610   \n",
      "converted                                 0.435914       0.053131   \n",
      "\n",
      "                          interaction_count  lead_score  converted  \n",
      "number_of_courses_viewed          -0.023565   -0.004879   0.435914  \n",
      "annual_income                      0.027036    0.015610   0.053131  \n",
      "interaction_count                  1.000000    0.009888   0.374573  \n",
      "lead_score                         0.009888    1.000000   0.193673  \n",
      "converted                          0.374573    0.193673   1.000000  \n",
      "Correlation between interaction_count and lead_score: 0.010\n",
      "Correlation between number_of_courses_viewed and lead_score: -0.005\n",
      "Correlation between number_of_courses_viewed and interaction_count: -0.024\n",
      "Correlation between annual_income and interaction_count: 0.027\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation matrix for numerical features\n",
    "correlation_matrix = df[numerical_columns].corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Extract the correlation values for the specified pairs\n",
    "pairs = {\n",
    "    \"interaction_count and lead_score\": correlation_matrix.loc[\"interaction_count\", \"lead_score\"],\n",
    "    \"number_of_courses_viewed and lead_score\": correlation_matrix.loc[\"number_of_courses_viewed\", \"lead_score\"],\n",
    "    \"number_of_courses_viewed and interaction_count\": correlation_matrix.loc[\"number_of_courses_viewed\", \"interaction_count\"],\n",
    "    \"annual_income and interaction_count\": correlation_matrix.loc[\"annual_income\", \"interaction_count\"]\n",
    "}\n",
    "\n",
    "for pair, corr_value in pairs.items():\n",
    "    print(f\"Correlation between {pair}: {corr_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d032546",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "- Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "- Use Scikit-Learn for that (the `train_test_split` function) and set the seed to `42`.\n",
    "- Make sure that the target value `converted` is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5895acf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (877, 8), Validation set: (292, 8), Test set: (293, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# separate features and target\n",
    "X = df.drop(columns=['converted'])\n",
    "y = df['converted']\n",
    "\n",
    "# Split the data into train (60%) and temp (40%)\n",
    "X_train_df, X_temp_df, y_train_df, y_temp_df = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Split the temp data into validation (20%) and test (20%)\n",
    "X_val_df, X_test_df, y_val_df, y_test_df = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the sizes of the splits\n",
    "print(f\"Train set: {X_train_df.shape}, Validation set: {X_val_df.shape}, Test set: {X_test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e95a25",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "- Calculate the mutual information score between `converted` and other categorical variables in the dataset. Use the training set only.\n",
    "- Round the scores to 2 decimals using `round(score, 2)`.\n",
    "\n",
    "Which of these variables has the biggest mutual information score?\n",
    "\n",
    "- `industry`\n",
    "- `location`\n",
    "- `lead_source` <---\n",
    "- `employment_status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8f41e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information between industry and converted: 0.02\n",
      "Mutual Information between location and converted: 0.0\n",
      "Mutual Information between lead_source and converted: 0.03\n",
      "Mutual Information between employment_status and converted: 0.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "# Calculate mutual information scores for categorical variables using the training set\n",
    "categorical_columns = ['industry', 'location', 'lead_source', 'employment_status']  # Only the relevant columns\n",
    "mutual_info_scores = {}\n",
    "\n",
    "for col in categorical_columns:\n",
    "    score = mutual_info_score(y_train_df, X_train_df[col])\n",
    "    mutual_info_scores[col] = round(score, 2)\n",
    "    print(f\"Mutual Information between {col} and converted: {round(score, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028f9b22",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "- Now let's train a logistic regression.\n",
    "- Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "- Fit the model on the training dataset.\n",
    "  - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "  - `model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)`\n",
    "- Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "\n",
    "What accuracy did you get?\n",
    "\n",
    "- 0.64\n",
    "- 0.74 <---\n",
    "- 0.84\n",
    "- 0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83bad3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train_dict = X_train_df.to_dict(orient='records')\n",
    "X_val_dict = X_val_df.to_dict(orient='records')\n",
    "\n",
    "# Apply DictVectorizer\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train = dv.fit_transform(X_train_dict)\n",
    "X_val = dv.transform(X_val_dict)\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train_df)\n",
    "\n",
    "# Make predictions on the validation\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val_df, y_pred)\n",
    "print(f\"Val Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97325b7",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "- Let's find the least useful feature using the _feature elimination_ technique.\n",
    "- Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "- Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "- For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "\n",
    "Which of following feature has the smallest difference?\n",
    "\n",
    "- `'industry'`\n",
    "- `'employment_status'`\n",
    "- `'lead_score'`\n",
    "\n",
    "> *All????*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4379615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 0.7432\n",
      "Feature accuracies difference:\n",
      "employment_status=NA: 0.0\n",
      "employment_status=employed: 0.0\n",
      "employment_status=student: 0.0\n",
      "industry=NA: 0.0\n",
      "industry=finance: 0.0\n",
      "industry=healthcare: 0.0\n",
      "industry=manufacturing: 0.0\n",
      "industry=other: 0.0\n",
      "industry=retail: 0.0\n",
      "industry=technology: 0.0\n",
      "lead_score: 0.0\n",
      "lead_source=NA: 0.0\n",
      "lead_source=events: 0.0\n",
      "lead_source=organic_search: 0.0\n",
      "lead_source=referral: 0.0\n",
      "lead_source=social_media: 0.0\n",
      "location=NA: 0.0\n",
      "location=africa: 0.0\n",
      "location=asia: 0.0\n",
      "location=australia: 0.0\n",
      "location=europe: 0.0\n",
      "location=middle_east: 0.0\n",
      "location=north_america: 0.0\n",
      "location=south_america: 0.0\n",
      "employment_status=self_employed: 0.003424657534246589\n",
      "employment_status=unemployed: 0.003424657534246589\n",
      "industry=education: 0.003424657534246589\n",
      "lead_source=paid_ads: 0.003424657534246589\n",
      "number_of_courses_viewed: 0.06506849315068486\n",
      "interaction_count: 0.06849315068493145\n",
      "annual_income: 0.113013698630137\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train_dict = X_train_df.to_dict(orient='records')\n",
    "X_val_dict = X_val_df.to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train = dv.fit_transform(X_train_dict)\n",
    "X_val = dv.transform(X_val_dict)\n",
    "\n",
    "# Train the model with all features\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train_df)\n",
    "y_pred = model.predict(X_val)\n",
    "original_accuracy = accuracy_score(y_val_df, y_pred)\n",
    "print(f\"Original Accuracy: {original_accuracy:.4f}\")\n",
    "\n",
    "# Feature elimination\n",
    "feature_accuracies = {}\n",
    "for feature in dv.feature_names_:\n",
    "    # Remove the feature - weird way to do it with numpy arrays (because of previous DictVectorizer)\n",
    "    reduced_X_train = X_train[:, [i for i, f in enumerate(dv.feature_names_) if f != feature]]\n",
    "    reduced_X_val = X_val[:, [i for i, f in enumerate(dv.feature_names_) if f != feature]]\n",
    "    \n",
    "    # Train the model without the feature\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model.fit(reduced_X_train, y_train_df)\n",
    "    y_pred = model.predict(reduced_X_val)\n",
    "    accuracy = accuracy_score(y_val_df, y_pred)\n",
    "    \n",
    "    # Record the accuracy difference (in absolute terms)\n",
    "    feature_accuracies[feature] = abs(accuracy - original_accuracy)\n",
    "    #print(f\"Accuracy without '{feature}': {accuracy} (Difference: {accuracy - original_accuracy})\")\n",
    "\n",
    "\n",
    "# Sort the feature_accuracies dictionary by values\n",
    "sorted_features = sorted(feature_accuracies.items(), key=lambda x: x[1])\n",
    "\n",
    "# Print the sorted features neatly\n",
    "print(\"Feature accuracies difference:\")\n",
    "for feature, diff in sorted_features:\n",
    "    print(f\"{feature}: {diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a712071",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "- Now let's train a regularized logistic regression.\n",
    "- Let's try the following values of the parameter `C`: `[0.01, 0.1, 1, 10, 100]`.\n",
    "- Train models using all the features as in Q4.\n",
    "- Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "\n",
    "Which of these `C` leads to the best accuracy on the validation set?\n",
    "\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- 10\n",
    "- 100\n",
    "\n",
    "> **Note**: If there are multiple options, select the smallest `C`.\n",
    "\n",
    "> *Answer* : It's all (???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a19b0da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01: Validation Accuracy = 0.743\n",
      "C=0.01, Coefficients: [[-1.54986308e-05 -1.38818400e-02  2.84473331e-02  1.65496841e-02\n",
      "   9.81712858e-03 -1.07635095e-01 -2.19118936e-02  5.30517813e-02\n",
      "  -2.55297090e-02 -2.24924091e-02 -1.22293827e-02 -5.50949851e-03\n",
      "  -1.69774363e-02 -1.51042417e-02  2.55041816e-01  4.30605564e-02\n",
      "   7.95353967e-03 -1.56486967e-02 -1.54810535e-02 -9.65766117e-02\n",
      "   6.94316344e-02 -1.63816017e-02  4.09622438e-03 -1.50863999e-02\n",
      "  -1.24810038e-02 -1.09627449e-02  3.26015378e-03  4.89975207e-03\n",
      "  -2.22195074e-02 -1.82092638e-02  4.16038439e-01]]\n",
      "C=0.1: Validation Accuracy = 0.743\n",
      "C=0.1, Coefficients: [[-1.82895893e-05 -1.35593994e-02  2.97880515e-02  1.80547407e-02\n",
      "   1.20330232e-02 -1.06401372e-01 -2.11179445e-02  5.40284235e-02\n",
      "  -2.50509542e-02 -2.16462414e-02 -1.14414537e-02 -4.19817699e-03\n",
      "  -1.61889333e-02 -1.44696750e-02  2.94243475e-01  4.66717056e-02\n",
      "   8.63902051e-03 -1.45953931e-02 -1.39296136e-02 -9.60066592e-02\n",
      "   7.10159078e-02 -1.52082181e-02  4.46134269e-03 -1.43986598e-02\n",
      "  -1.19150253e-02 -9.87061437e-03  4.48341471e-03  6.38182271e-03\n",
      "  -2.11894959e-02 -1.80377405e-02  4.47459453e-01]]\n",
      "C=1: Validation Accuracy = 0.743\n",
      "C=1, Coefficients: [[-1.85981761e-05 -1.35111322e-02  2.99224880e-02  1.82178695e-02\n",
      "   1.22843588e-02 -1.06173888e-01 -2.10082113e-02  5.41017584e-02\n",
      "  -2.49752388e-02 -2.15300885e-02 -1.13399746e-02 -4.04064976e-03\n",
      "  -1.60840620e-02 -1.43838370e-02  2.98640270e-01  4.70610362e-02\n",
      "   8.71290786e-03 -1.44604312e-02 -1.37361363e-02 -9.58653120e-02\n",
      "   7.11476246e-02 -1.50589565e-02  4.50077429e-03 -1.43065964e-02\n",
      "  -1.18392102e-02 -9.73476910e-03  4.62393212e-03  6.55132004e-03\n",
      "  -2.10520303e-02 -1.80037241e-02  4.50797525e-01]]\n",
      "C=10: Validation Accuracy = 0.743\n",
      "C=10, Coefficients: [[-1.86293569e-05 -1.35061207e-02  2.99359253e-02  1.82343179e-02\n",
      "   1.23098224e-02 -1.06149932e-01 -2.09968897e-02  5.41087997e-02\n",
      "  -2.49673457e-02 -2.15181112e-02 -1.13295678e-02 -4.02459895e-03\n",
      "  -1.60732768e-02 -1.43749967e-02  2.99085204e-01  4.71002701e-02\n",
      "   8.72035358e-03 -1.44465970e-02 -1.37163529e-02 -9.58501959e-02\n",
      "   7.11604713e-02 -1.50436664e-02  4.50474869e-03 -1.42971233e-02\n",
      "  -1.18314085e-02 -9.72088186e-03  4.63818674e-03  6.56850680e-03\n",
      "  -2.10378890e-02 -1.80001267e-02  4.51133377e-01]]\n",
      "C=100: Validation Accuracy = 0.743\n",
      "C=100, Coefficients: [[-1.86324786e-05 -1.35056177e-02  2.99372690e-02  1.82359641e-02\n",
      "   1.23123721e-02 -1.06147524e-01 -2.09957540e-02  5.41095008e-02\n",
      "  -2.49665531e-02 -2.15169098e-02 -1.13285245e-02 -4.02299085e-03\n",
      "  -1.60721953e-02 -1.43741100e-02  2.99129750e-01  4.71041965e-02\n",
      "   8.72109872e-03 -1.44452101e-02 -1.37143701e-02 -9.58486743e-02\n",
      "   7.11617527e-02 -1.50421337e-02  4.50514645e-03 -1.42961733e-02\n",
      "  -1.18306261e-02 -9.71949007e-03  4.63961426e-03  6.57022788e-03\n",
      "  -2.10364709e-02 -1.79997650e-02  4.51166983e-01]]\n",
      "\n",
      "Accuracies for different values of C:\n",
      "C=0.01: 0.7431506849315068\n",
      "C=0.1: 0.7431506849315068\n",
      "C=1: 0.7431506849315068\n",
      "C=10: 0.7431506849315068\n",
      "C=100: 0.7431506849315068\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "accuracies = {}\n",
    "\n",
    "for C in C_values:\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train_df)\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val_df, y_pred)\n",
    "    accuracies[C] = accuracy\n",
    "    print(f\"C={C}: Validation Accuracy = {accuracy:.3f}\")\n",
    "    print(f\"C={C}, Coefficients: {model.coef_}\")\n",
    "\n",
    "print(\"\\nAccuracies for different values of C:\")\n",
    "for C, acc in accuracies.items():\n",
    "    print(f\"C={C}: {acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
